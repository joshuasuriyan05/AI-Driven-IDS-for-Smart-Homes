# Load Datasets

from datasets import load_dataset
import pandas as pd
dataset = load_dataset("codymlewis/TON_IoT_network")
#orginal dataset input
df_train = dataset["train"].to_pandas()
df_test  = dataset["test"].to_pandas()

print(df_train.shape, df_test.shape)
-------------------------------------------------------------------------------

# Label Processing

df_train['label'] = df_train['label'].astype(int)
df_test['label']  = df_test['label'].astype(int)
--------------------------------------------------------------------------------

# Feature Selection

drop_cols = [
    'src_ip','dst_ip','dns_query','ssl_subject','ssl_issuer',
    'http_uri','http_user_agent','http_orig_mime_types',
    'http_resp_mime_types','weird_name','weird_addl','type'
]

df_train.drop(columns=drop_cols, inplace=True, errors='ignore')
df_test.drop(columns=drop_cols, inplace=True, errors='ignore')
-----------------------------------------------------------------------------------------
# Encode Categorical + Scale Numeric Features

from sklearn.preprocessing import StandardScaler

cat_cols = df_train.select_dtypes(include='object').columns
df_all = pd.concat([df_train, df_test])

df_all = pd.get_dummies(df_all, columns=cat_cols)

X = df_all.drop('label', axis=1)
y = df_all['label']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
------------------------------------------------------------------------------------------------
# Model-Ready Input(Features)

X_train = X_scaled[:len(df_train)]
X_test  = X_scaled[len(df_train):]

y_train = y.iloc[:len(df_train)]
y_test  = y.iloc[len(df_train):]
--------------------------------------------------------------------------------------------------
#  Creating Fedearted Clients

from sklearn.model_selection import StratifiedKFold

NUM_CLIENTS = 5
skf = StratifiedKFold(n_splits=NUM_CLIENTS, shuffle=True, random_state=42)

X_clients, y_clients = [], []

for _, idx in skf.split(X_train, y_train):
    #Federated Learning inputs data split into clients
    X_clients.append(X_train[idx])
    y_clients.append(y_train.iloc[idx].values)

print("Federated Clients:", len(X_clients))
-----------------------------------------------------------------------------------------------------
# FedAvg(Neural Networks)

import tensorflow as tf
import numpy as np

def create_model(input_dim):
    model = tf.keras.Sequential([
        tf.keras.Input(shape=(input_dim,)),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(32, activation='relu'),
        tf.keras.layers.Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam',
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    return model

global_model = create_model(X_train.shape[1])

ROUNDS = 3

for r in range(ROUNDS):
    client_weights = []

    for i in range(NUM_CLIENTS):
        local_model = create_model(X_train.shape[1])
        local_model.set_weights(global_model.get_weights())
        #Input to local models
        local_model.fit(X_clients[i], y_clients[i],
                        epochs=2, batch_size=512, verbose=0)
        #ouputs of local models
        client_weights.append(local_model.get_weights())

    new_weights = [np.mean(w, axis=0) for w in zip(*client_weights)]
    #Global model output
    global_model.set_weights(new_weights)
-------------------------------------------------------------------------------------------------------
# Federated Random Forest

from sklearn.ensemble import RandomForestClassifier

rf_models = []

for i in range(NUM_CLIENTS):
    rf = RandomForestClassifier(
        n_estimators=200,
        max_depth=20,
        random_state=42,
        n_jobs=-1
    )
    #Input to each client model
    rf.fit(X_clients[i], y_clients[i])
    #output stored
    rf_models.append(rf)
---------------------------------------------------------------------------------------------------------------
# Federated Gradient Boosting

from sklearn.ensemble import GradientBoostingClassifier

gb_models = []

for i in range(NUM_CLIENTS):
    if len(np.unique(y_clients[i])) < 2:
        continue
    gb = GradientBoostingClassifier(
        n_estimators=150,
        learning_rate=0.05,
        max_depth=3
    )
    #input
    gb.fit(X_clients[i], y_clients[i])
    #output stored
    gb_models.append(gb)
-----------------------------------------------------------------------------------------------------------
# Federated Ensemble(Soft Voting)

def federated_probs(models, X):
    probs = np.zeros(len(X))
    for m in models:
        probs += m.predict_proba(X)[:,1]
    return probs / len(models)
#Input to Ensemble
rf_probs = federated_probs(rf_models, X_test)
gb_probs = federated_probs(gb_models, X_test)
#Ensemble Output Stored
ensemble_probs = (rf_probs + gb_probs) / 2
y_pred = (ensemble_probs > 0.5).astype(int)
----------------------------------------------------------------------------------------------------------
# Performance Metrics + Attacks Detected

from sklearn.metrics import (
    accuracy_score, classification_report,
    confusion_matrix, roc_auc_score, roc_curve
)

accuracy = accuracy_score(y_test, y_pred)
#Confusion Matrix and Counts
cm = confusion_matrix(y_test, y_pred)
tn, fp, fn, tp = cm.ravel()

print("Accuracy:", accuracy)
print("Attacks Detected (TP):", tp)
print("Normal Traffic Correct (TN):", tn)
print(classification_report(y_test, y_pred))
------------------------------------------------------------------------------------------------------
# ROC Curve and AUC

import matplotlib.pyplot as plt
#ROC and AUC Output
roc_auc = roc_auc_score(y_test, ensemble_probs)
fpr, tpr, _ = roc_curve(y_test, ensemble_probs)

plt.figure(figsize=(6,5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.4f}")
plt.plot([0,1],[0,1],'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve â€“ Federated Ensemble IDS")
plt.legend()
plt.grid()
plt.show()
-----------------------------------------------------------------------------------------------------------

